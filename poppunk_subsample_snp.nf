#!/usr/bin/env nextflow
nextflow.enable.dsl=2

/* ----------------------------------------------------------
 * PARAMETERS
 * ---------------------------------------------------------- */

println "â–¶ FASTA input directory:  ${params.input}"
println "â–¶ Results directory:      ${params.resultsDir}"
println "â–¶ Threads / RAM:          ${params.threads}  /  ${params.ram}"

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * 1 â–¸ Validate FASTA files and filter out empty ones
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
process VALIDATE_FASTA {
    tag         'validate_fasta'
    container   'python:3.9'
    cpus        8
    memory      '16 GB'
    publishDir  "${params.resultsDir}/validation", mode: 'copy'

    input:
    path fasta_files

    output:
    path 'valid_files.list', emit: valid_list
    path 'validation_report.txt', emit: report

    script:
    """
    python - << 'PY'
import os
from pathlib import Path

valid_files = []
invalid_files = []
total_files = 0

# Process each FASTA file
fasta_files = '${fasta_files}'.split()
for fasta_file in fasta_files:
    total_files += 1
    file_path = Path(fasta_file)
    
    # Get the absolute path for the file
    abs_path = file_path.resolve()
    
    if not file_path.exists():
        invalid_files.append(f"{fasta_file}: File does not exist")
        continue
    
    if file_path.stat().st_size == 0:
        invalid_files.append(f"{fasta_file}: File is empty (0 bytes)")
        continue
    
    # Check if file contains actual sequence data
    has_sequence = False
    sequence_length = 0
    
    try:
        with open(fasta_file, 'r') as f:
            lines = f.readlines()
            for line in lines:
                line = line.strip()
                if line and not line.startswith('>'):
                    sequence_length += len(line)
                    has_sequence = True
        
        if not has_sequence or sequence_length == 0:
            invalid_files.append(f"{fasta_file}: No sequence data found")
        elif sequence_length < 1000:  # Minimum sequence length threshold
            invalid_files.append(f"{fasta_file}: Sequence too short ({sequence_length} bp)")
        else:
            # Store the absolute path so MASH can find the files
            valid_files.append(str(abs_path))
            
    except Exception as e:
        invalid_files.append(f"{fasta_file}: Error reading file - {str(e)}")

# Write valid files list with absolute paths
with open('valid_files.list', 'w') as f:
    for valid_file in valid_files:
        f.write(f"{valid_file}\\n")

# Write validation report
with open('validation_report.txt', 'w') as f:
    f.write(f"FASTA Validation Report\\n")
    f.write(f"======================\\n")
    f.write(f"Total files processed: {total_files}\\n")
    f.write(f"Valid files: {len(valid_files)}\\n")
    f.write(f"Invalid files: {len(invalid_files)}\\n\\n")
    
    if valid_files:
        f.write("Valid files (with absolute paths):\\n")
        for vf in valid_files:
            f.write(f"  âœ“ {vf}\\n")
        f.write("\\n")
    
    if invalid_files:
        f.write("Invalid files (excluded from analysis):\\n")
        for inf in invalid_files:
            f.write(f"  âœ— {inf}\\n")

print(f"Validation complete: {len(valid_files)} valid files out of {total_files} total files")
if len(valid_files) < 3:
    print("WARNING: Less than 3 valid files found. PopPUNK requires at least 3 genomes.")
    exit(1)
PY
    """
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * 2 â–¸ MASH sketch every valid .fasta
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
process MASH_SKETCH {
    tag         'mash_sketch'
    container 'quay.io/biocontainers/mash:2.3--hb105d93_9'
    cpus        { params.threads }
    memory      { params.ram }

    input:
    path fasta_files

    output:
    path 'mash.msh'      , emit: msh
    path 'all_files.list', emit: list

    script:
    """
    # Create file list with staged filenames (not absolute paths)
    ls *.fasta > all_files.list
    
    # Check if we have any files to process
    if [ ! -s all_files.list ]; then
        echo "ERROR: No valid FASTA files found for sketching"
        exit 1
    fi
    
    echo "Sketching \$(wc -l < all_files.list) valid FASTA files..."
    echo "First few files to be processed:"
    head -5 all_files.list
    
    echo "All files verified. Starting MASH sketching..."
    
    mash sketch -p ${task.cpus} -k ${params.mash_k} -s ${params.mash_s} \\
        -o mash.msh -l all_files.list
        
    echo "MASH sketching completed successfully!"
    """
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * 2 â–¸ Mash pairwise distances
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
process MASH_DIST {
    tag         'mash_dist'
    container 'quay.io/biocontainers/mash:2.3--hb105d93_9'
    cpus        32
    memory      '64 GB'

    input:
    path msh

    output:
    path 'mash.dist'

    script:
    """
    echo "Computing pairwise distances for all genomes..."
    mash dist -p ${task.cpus} ${msh} ${msh} > mash.dist
    echo "Distance computation completed. Generated \$(wc -l < mash.dist) pairwise comparisons."
    """
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * 3 â–¸ Bin genomes & subsample
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
process BIN_SUBSAMPLE {
    tag         'bin_subsample'
    container 'python:3.9'
    cpus        16
    memory      '32 GB'

    input:
    path dist_file

    output:
    path 'subset.list'

    script:
    """
    pip install --quiet networkx
    python - << 'PY'
import networkx as nx, random, sys, pathlib, os

print("Building similarity graph from MASH distances...")

# This is the absolute path to your main input directory
input_dir = "${params.input}"

G = nx.Graph()
# Process the mash distance file - files are now relative filenames
for line in open('${dist_file}'):
    a, b, d, *_ = line.split()
    if float(d) < ${params.mash_thresh}:
        G.add_edge(a, b)

print(f"Graph built with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges")
print(f"Found {nx.number_connected_components(G)} connected components")

with open('subset.list','w') as out:
    total_selected = 0
    for i, comp in enumerate(nx.connected_components(G)):
        comp = list(comp)
        k = min(45, max(3, len(comp)//10))
        k = min(k, len(comp))
        if k > 0:
            selected = random.sample(comp, k)
            for filename in selected:
                # Create a sample name from the filename
                sample_name = os.path.splitext(filename)[0]
                # Create the full absolute path for PopPUNK to use
                full_path = os.path.join(input_dir, filename)
                out.write(f"{sample_name}\\t{full_path}\\n")
                total_selected += 1
        print(f"Component {i+1}: {len(comp)} genomes -> selected {k} representatives")

print(f"Total genomes selected for PopPUNK modeling: {total_selected}")
PY
    """
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * 4 â–¸ Build PopPUNK model on subset
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
process POPPUNK_MODEL {
    tag          'poppunk_model'
    container    'staphb/poppunk:2.6.2'
    cpus         { params.threads }
    memory       { params.ram }
    publishDir   "${params.resultsDir}/poppunk_model", mode: 'copy'

    input:
    path sub_list
    path fasta_files

    output:
    path 'poppunk_db', type: 'dir', emit: db
    path 'cluster_model.csv'     , emit: csv
    path 'staged_files.list'     , emit: staged_list

    script:
    """
    # Check if subset list is not empty
    if [ ! -s ${sub_list} ]; then
        echo "ERROR: Subset list is empty. No valid genomes found for PopPUNK modeling."
        exit 1
    fi
    
    echo "Building PopPUNK database with \$(wc -l < ${sub_list}) genomes..."
    
    # Create a new file list with staged filenames (not absolute paths)
    # Map the sample names from subset.list to the staged FASTA files
    > staged_files.list
    while IFS=\$'\\t' read -r sample_name file_path; do
        # Find the corresponding staged file
        basename_file=\$(basename "\$file_path")
        if [ -f "\$basename_file" ]; then
            echo -e "\$sample_name\\t\$basename_file" >> staged_files.list
            echo "Mapped: \$sample_name -> \$basename_file"
        else
            echo "ERROR: Staged file not found: \$basename_file"
            exit 1
        fi
    done < ${sub_list}
    
    echo "Created staged files list:"
    cat staged_files.list
    
    echo "All files verified. Starting PopPUNK database creation..."
    
    poppunk --create-db --r-files staged_files.list \\
        --output poppunk_db --threads ${task.cpus}

    echo "Database created successfully. Fitting model..."
    
    poppunk --fit-model bgmm --ref-db poppunk_db \\
        --output poppunk_fit --threads ${task.cpus}

    echo "Model fitting completed. Copying fitted model files to database directory..."
    
    # Copy all fitted model files from poppunk_fit to poppunk_db
    # This ensures the database directory contains both the database and the fitted model
    if [ -d "poppunk_fit" ]; then
        echo "Copying fitted model files to poppunk_db directory..."
        
        # Copy all files from poppunk_fit to poppunk_db
        cp poppunk_fit/* poppunk_db/ 2>/dev/null || echo "Some files could not be copied"
        
        # The critical step: rename the fitted model file to match what PopPUNK expects
        if [ -f "poppunk_db/poppunk_fit_fit.pkl" ]; then
            cp poppunk_db/poppunk_fit_fit.pkl poppunk_db/poppunk_db_fit.pkl
            echo "âœ“ Created poppunk_db_fit.pkl from poppunk_fit_fit.pkl"
        fi
        
        # Also copy the npz file with the correct name
        if [ -f "poppunk_db/poppunk_fit_fit.npz" ]; then
            cp poppunk_db/poppunk_fit_fit.npz poppunk_db/poppunk_db_fit.npz
            echo "âœ“ Created poppunk_db_fit.npz from poppunk_fit_fit.npz"
        fi
        
        echo "Files in poppunk_db after copying:"
        ls -la poppunk_db/
        
        # Verify the critical model file exists
        if [ -f "poppunk_db/poppunk_db_fit.pkl" ]; then
            echo "âœ“ Found fitted model file: poppunk_db_fit.pkl"
        else
            echo "âš  Model .pkl file not found. Available files:"
            ls -la poppunk_db/*.pkl 2>/dev/null || echo "No .pkl files found"
        fi
    else
        echo "ERROR: poppunk_fit directory not found"
        exit 1
    fi

    # Check for different possible output file locations for cluster assignments
    if [ -f "poppunk_fit/poppunk_fit_clusters.csv" ]; then
        cp poppunk_fit/poppunk_fit_clusters.csv cluster_model.csv
        echo "Found poppunk_fit_clusters.csv in poppunk_fit/"
    elif [ -f "poppunk_fit/cluster_assignments.csv" ]; then
        cp poppunk_fit/cluster_assignments.csv cluster_model.csv
        echo "Found cluster_assignments.csv in poppunk_fit/"
    elif ls poppunk_fit/*_clusters.csv 1> /dev/null 2>&1; then
        cp poppunk_fit/*_clusters.csv cluster_model.csv
        echo "Found cluster file in poppunk_fit/"
    elif ls poppunk_fit/*.csv 1> /dev/null 2>&1; then
        cp poppunk_fit/*.csv cluster_model.csv
        echo "Found CSV file in poppunk_fit/"
    else
        echo "Available files in poppunk_fit/:"
        ls -la poppunk_fit/ || echo "poppunk_fit directory not found"
        echo "Available files in current directory:"
        ls -la *.csv || echo "No CSV files found"
        # Create a minimal output file so the pipeline doesn't fail
        echo "sample,cluster" > cluster_model.csv
        echo "PopPUNK completed but cluster assignments file not found in expected location"
    fi
    
    echo "PopPUNK model completed successfully!"
    """
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * 5 â–¸ Assign *all* genomes to that model
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
process POPPUNK_ASSIGN {
    tag          'poppunk_assign'
    container    'staphb/poppunk:2.6.2'
    cpus         { params.threads }
    memory       { params.ram }
    publishDir   "${params.resultsDir}/poppunk_full", mode: 'copy'

    input:
    path db_dir
    path list_file
    path fasta_files

    output:
    path 'full_assign.csv'

    script:
    """
    # Create a staged file list for all FASTA files
    ls *.fasta > staged_all_files.list
    
    echo "Assigning \$(wc -l < staged_all_files.list) genomes to PopPUNK clusters..."
    echo "First few files:"
    head -5 staged_all_files.list
    
    poppunk --use-model --ref-db ${db_dir} \\
        --r-files staged_all_files.list \\
        --output poppunk_full \\
        --threads ${task.cpus}

    cp poppunk_full/cluster_assignments.csv full_assign.csv
    
    echo "PopPUNK assignment completed successfully!"
    """
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * MAIN WORKFLOW
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
workflow {

    ch_fasta = Channel.fromPath("${params.input}/*.fasta", checkIfExists: true)
    
    // Validate FASTA files first
    validation_out = VALIDATE_FASTA(ch_fasta.collect())
    
    // Display validation report
    validation_out.report.view { report -> 
        println "\n" + "="*50
        println "ðŸ“‹ FASTA VALIDATION REPORT"
        println "="*50
        println report.text
        println "="*50 + "\n"
    }
    
    // Filter the original FASTA files based on validation results
    // Read the valid files list and create a channel of valid files
    valid_files_ch = validation_out.valid_list
        .splitText() { it.trim() }
        .map { file_path -> file(file_path) }
        .filter { it.exists() }
    
    // Collect valid files for use in multiple processes
    valid_files_collected = valid_files_ch.collect()
    
    sketch_out = MASH_SKETCH(valid_files_collected)
    dist_ch    = MASH_DIST(sketch_out.msh)
    subset_ch  = BIN_SUBSAMPLE(dist_ch)
    model_out  = POPPUNK_MODEL(subset_ch, valid_files_collected)
    final_csv  = POPPUNK_ASSIGN(model_out.db, sketch_out.list, valid_files_collected)

    final_csv.view { p -> "âœ… PopPUNK assignment written: ${p}" }
}
